<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Problem OverviewIn this part, we will try to understand the idea of Softmax classifier and use this algorithm for the picture classification and see the difference between Softmax and SVM. To be more">
<meta property="og:type" content="article">
<meta property="og:title" content="Softmax">
<meta property="og:url" content="http://yoursite.com/2020/02/16/Softmax/index.html">
<meta property="og:site_name" content="BaniaBlog">
<meta property="og:description" content="Problem OverviewIn this part, we will try to understand the idea of Softmax classifier and use this algorithm for the picture classification and see the difference between Softmax and SVM. To be more">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581826848602.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581826764671.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581827688934.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581828245723.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581828320014.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581828939035.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581828963231.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581829212177.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581829307591.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581829383085.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581829600085.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581829619119.png">
<meta property="og:image" content="http://yoursite.com/2020/02/16/Softmax/1581829896775.png">
<meta property="article:published_time" content="2020-02-16T02:43:59.000Z">
<meta property="article:modified_time" content="2020-02-16T09:08:55.022Z">
<meta property="article:author" content="Bania">
<meta property="article:tag" content="Python">
<meta property="article:tag" content=" Java">
<meta property="article:tag" content=" Machine Learning">
<meta property="article:tag" content=" Data Science">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/02/16/Softmax/1581826848602.png">

<link rel="canonical" href="http://yoursite.com/2020/02/16/Softmax/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Softmax | BaniaBlog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="BaniaBlog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">BaniaBlog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Sharing Technology</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/Zbx2017/Zbx2017.github.io" class="github-corner" title="Bania GitHub" aria-label="Bania GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
    
  
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/16/Softmax/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bania">
      <meta itemprop="description" content="A platform for discussing programming and technology">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BaniaBlog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Softmax
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-02-16 10:43:59 / Modified: 17:08:55" itemprop="dateCreated datePublished" datetime="2020-02-16T10:43:59+08:00">2020-02-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h4 id="Problem-Overview"><a href="#Problem-Overview" class="headerlink" title="Problem Overview"></a>Problem Overview</h4><p>In this part, we will try to understand the idea of Softmax classifier and use this algorithm for the picture classification and see the difference between Softmax and SVM. To be more specific, we will solve the problems below:</p>
<ul>
<li>implement a fully-vectorized <strong>loss function</strong> for the Softmax classifier</li>
<li>implement the fully-vectorized expression for its <strong>analytic gradient</strong></li>
<li><strong>check your implementation</strong> with numerical gradient</li>
<li>use a validation set to <strong>tune the learning rate and regularization</strong> strength</li>
<li><strong>optimize</strong> the loss function with <strong>SGD</strong></li>
<li><strong>visualize</strong> the final learned weights</li>
</ul>
<p>Actually, this exercise is quit analogous to the SVM exercise. The most different is the loss function of Softmax. Now, we are going to have a clear idea of Softmax first and then realize the algorithm with the code. </p>
<h4 id="Softmax-Explaintion"><a href="#Softmax-Explaintion" class="headerlink" title="Softmax Explaintion"></a>Softmax Explaintion</h4><p>In SVM, we use hinge loss as its loss function, which treats scores for each class. Now, for Softmax, we not only have to get the scores for each class, but also need to normalize them and finally obtain the probabilities of each class. The loss function we use here is cross-entropy loss:</p>
<p><img src="/2020/02/16/Softmax/1581826848602.png" alt="1581826848602"></p>
<p><img src="/2020/02/16/Softmax/1581826764671.png" alt="1581826764671"></p>
<p>To be honest, the calculation of cross-entropy loss is easier than hinge loss. There are no other limited  conditions and it is more straightforward. But the only thing you should pay attention to is the numerical stability. Notice that the scores for each class may be huge numbers and the exp(f) can be very large so that dividing large numbers can be unstable. When I first did this problem I did not take care of this issue and the loss I got is very large and is not closed to -log(0.1). Then I changed my algorithm by adding a constant C to eliminate the instability.  </p>
<p><img src="/2020/02/16/Softmax/1581827688934.png" alt="1581827688934"></p>
<p>A common choice for C is to set log C = -max(f). This will simply states that we should shift the value inside the vector f so that the highest value is zero, so that the exp(f) will not be very large. </p>
<p>The most troublesome problem is the calculation of dW. I have gone through many troubles because of unfamiliarity with matrix derivative.  Using the chain rule and flexible matrix derivate will simplify the calculation, which makes it easy to code. I have searched other people’s method for this problem and I clearly know how it works. </p>
<p><img src="/2020/02/16/Softmax/1581828245723.png" alt="1581828245723"></p>
<p><img src="/2020/02/16/Softmax/1581828320014.png" alt="1581828320014"></p>
<p><img src="/2020/02/16/Softmax/1581828939035.png" alt="1581828939035"></p>
<p><img src="/2020/02/16/Softmax/1581828963231.png" alt="1581828963231"></p>
<p>Then we can easily obtain dW using this method. Here is the code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle</span><br><span class="line"><span class="keyword">from</span> past.builtins <span class="keyword">import</span> xrange</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">  Softmax loss function, naive implementation (with loops)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Inputs have dimension D, there are C classes, and we operate on minibatches</span></span><br><span class="line"><span class="string">  of N examples.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Inputs:</span></span><br><span class="line"><span class="string">  - W: A numpy array of shape (D, C) containing weights.</span></span><br><span class="line"><span class="string">  - X: A numpy array of shape (N, D) containing a minibatch of data.</span></span><br><span class="line"><span class="string">  - y: A numpy array of shape (N,) containing training labels; y[i] = c means</span></span><br><span class="line"><span class="string">    that X[i] has label c, where 0 &lt;= c &lt; C.</span></span><br><span class="line"><span class="string">  - reg: (float) regularization strength</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns a tuple of:</span></span><br><span class="line"><span class="string">  - loss as single float</span></span><br><span class="line"><span class="string">  - gradient with respect to weights W; an array of same shape as W</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  <span class="comment"># Initialize the loss and gradient to zero.</span></span><br><span class="line">    </span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line"></span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line">  <span class="comment"># <span class="doctag">TODO:</span> Compute the softmax loss and its gradient using explicit loops.     #</span></span><br><span class="line">  <span class="comment"># Store the loss in loss and the gradient in dW. If you are not careful     #</span></span><br><span class="line">  <span class="comment"># here, it is easy to run into numeric instability. Don't forget the        #</span></span><br><span class="line">  <span class="comment"># regularization!                                                           #</span></span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line">    num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_train):</span><br><span class="line">        </span><br><span class="line">        scores = X[i].dot(W)</span><br><span class="line">        scores -= np.max(scores)</span><br><span class="line">        correct_score = scores[y[i]]</span><br><span class="line">        sum_scores = np.sum(np.exp(scores))</span><br><span class="line">        loss += np.log(sum_scores) - correct_score</span><br><span class="line">        dW[:,y[i]] -= X[i].T </span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_classes):</span><br><span class="line">            </span><br><span class="line">            dW[:,j] += (np.exp(scores[j])/sum_scores * X[i]).T</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    loss /= num_train</span><br><span class="line">    loss += reg*np.sum(W*W)</span><br><span class="line">    dW /= num_train</span><br><span class="line">    dW += <span class="number">2</span>*reg*W</span><br><span class="line">            </span><br><span class="line">  </span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line">  <span class="comment">#                          END OF YOUR CODE                                 #</span></span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">  Softmax loss function, vectorized version.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Inputs and outputs are the same as softmax_loss_naive.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">  <span class="comment"># Initialize the loss and gradient to zero.</span></span><br><span class="line">    </span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    dW = np.zeros_like(W)</span><br><span class="line"></span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line">  <span class="comment"># <span class="doctag">TODO:</span> Compute the softmax loss and its gradient using no explicit loops.  #</span></span><br><span class="line">  <span class="comment"># Store the loss in loss and the gradient in dW. If you are not careful     #</span></span><br><span class="line">  <span class="comment"># here, it is easy to run into numeric instability. Don't forget the        #</span></span><br><span class="line">  <span class="comment"># regularization!                                                           #</span></span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line">    num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">    scores = X.dot(W)</span><br><span class="line">    scores -= np.max(scores, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    correct_scores = scores[np.arange(num_train),y]</span><br><span class="line">    pro_scores = np.exp(scores)/ np.sum(np.exp(scores), axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    loss += -np.sum(np.log(pro_scores[np.arange(num_train),y]))</span><br><span class="line">    </span><br><span class="line">    pro_scores[np.arange(num_train),y] += <span class="number">-1</span> </span><br><span class="line">    dW += X.T.dot(pro_scores)</span><br><span class="line">    </span><br><span class="line">    loss /= num_train</span><br><span class="line">    dW /= num_train</span><br><span class="line">    </span><br><span class="line">    loss += reg*np.sum(W*W)</span><br><span class="line">    dW += <span class="number">2</span>*reg*W</span><br><span class="line">    </span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line">  <span class="comment">#                          END OF YOUR CODE                                 #</span></span><br><span class="line">  <span class="comment">#############################################################################</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, dW</span><br></pre></td></tr></table></figure>
<h4 id="Check-You-Code"><a href="#Check-You-Code" class="headerlink" title="Check You Code"></a>Check You Code</h4><p>Just like the SVM exercise, you can use the method provided to check your code. Before it you have to load the data. As it is the same with SVM, I am not going to show it here and turn to the checking process directly.</p>
<p>Check the loss: the loss you calculate should be close to 2.302585, if not check you algorithm. </p>
<p><img src="/2020/02/16/Softmax/1581829212177.png" alt="1581829212177"></p>
<p>Check the gradient: numerical gradient and analytical gradient should be very close. </p>
<p><img src="/2020/02/16/Softmax/1581829307591.png" alt="1581829307591"></p>
<p>Then you can see the running time of using naive method and vetorized method. </p>
<p><img src="/2020/02/16/Softmax/1581829383085.png" alt="1581829383085"></p>
<h4 id="Cross-Validation-Getting-the-Best-Model"><a href="#Cross-Validation-Getting-the-Best-Model" class="headerlink" title="Cross Validation: Getting the Best Model"></a>Cross Validation: Getting the Best Model</h4><p>Finally, if all processes have been done successfully, which means the algorithm you write is correctly, then you can go to next step: training your model by using cross validation. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use the validation set to tune hyperparameters (regularization strength and</span></span><br><span class="line"><span class="comment"># learning rate). You should experiment with different ranges for the learning</span></span><br><span class="line"><span class="comment"># rates and regularization strengths; if you are careful you should be able to</span></span><br><span class="line"><span class="comment"># get a classification accuracy of over 0.35 on the validation set.</span></span><br><span class="line"><span class="keyword">from</span> cs231n.classifiers <span class="keyword">import</span> Softmax</span><br><span class="line">results = &#123;&#125;</span><br><span class="line">best_val = <span class="number">-1</span></span><br><span class="line">best_softmax = <span class="literal">None</span></span><br><span class="line">learning_rates = [<span class="number">1e-7</span>, <span class="number">1.2e-7</span>,<span class="number">1.4e-7</span>,<span class="number">1.6e-7</span>,<span class="number">1.8e-7</span>,<span class="number">2.0e-7</span>]</span><br><span class="line">regularization_strengths = [<span class="number">2.5e4</span>, <span class="number">2.7e4</span>,<span class="number">2.9e4</span>,<span class="number">3.1e4</span>,<span class="number">3.3e4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span>                                                                        #</span></span><br><span class="line"><span class="comment"># Use the validation set to set the learning rate and regularization strength. #</span></span><br><span class="line"><span class="comment"># This should be identical to the validation that you did for the SVM; save    #</span></span><br><span class="line"><span class="comment"># the best trained softmax classifer in best_softmax.                          #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="keyword">for</span> lr_i <span class="keyword">in</span> learning_rates:</span><br><span class="line">    <span class="keyword">for</span> rs_i <span class="keyword">in</span> regularization_strengths:</span><br><span class="line">        softmax = Softmax()</span><br><span class="line">        softmax.train(X_train, y_train, learning_rate=lr_i, reg=rs_i,num_iters=<span class="number">500</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">        y_train_pred = softmax.predict(X_train)</span><br><span class="line">        y_val_pred = softmax.predict(X_val)</span><br><span class="line">        y_train_acc = np.mean(y_train == y_train_pred)</span><br><span class="line">        y_val_acc = np.mean(y_val == y_val_pred)</span><br><span class="line">        results[(lr_i, rs_i)] = y_train_acc , y_val_acc</span><br><span class="line">        <span class="keyword">if</span> y_val_acc &gt; best_val:</span><br><span class="line">            best_val = y_val_acc</span><br><span class="line">            best_softmax =softmax</span><br><span class="line"></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line"><span class="comment">#                              END OF YOUR CODE                                #</span></span><br><span class="line"><span class="comment">################################################################################</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Print out results.</span></span><br><span class="line"><span class="keyword">for</span> lr, reg <span class="keyword">in</span> sorted(results):</span><br><span class="line">    train_accuracy, val_accuracy = results[(lr, reg)]</span><br><span class="line">    print(<span class="string">'lr %e reg %e train accuracy: %f val accuracy: %f'</span> % (</span><br><span class="line">                lr, reg, train_accuracy, val_accuracy))</span><br><span class="line">    </span><br><span class="line">print(<span class="string">'best validation accuracy achieved during cross-validation: %f'</span> % best_val)</span><br></pre></td></tr></table></figure>
<p>Then use the best model to predict the testing data. </p>
<p><img src="/2020/02/16/Softmax/1581829600085.png" alt="1581829600085"></p>
<p><img src="/2020/02/16/Softmax/1581829619119.png" alt="1581829619119"></p>
<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>As we can see, using softmax performs not as well as SVM in this problem. The distinction between them can be shown by a graph below:</p>
<p><img src="/2020/02/16/Softmax/1581829896775.png" alt="1581829896775"></p>
<p>The Softmax classifier is never fully happy with the scores it produces: the correct class could always have a higher probability and the incorrect classes always a lower probability and the loss would always get better. However, the SVM is happy once the margins are satisfied and it does not micromanage the exact scores beyond this constraint.</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/14/SVM/" rel="prev" title="SVM">
      <i class="fa fa-chevron-left"></i> SVM
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/18/Neural-Net/" rel="next" title="Neural Net">
      Neural Net <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Problem-Overview"><span class="nav-number">1.</span> <span class="nav-text">Problem Overview</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmax-Explaintion"><span class="nav-number">2.</span> <span class="nav-text">Softmax Explaintion</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Check-You-Code"><span class="nav-number">3.</span> <span class="nav-text">Check You Code</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cross-Validation-Getting-the-Best-Model"><span class="nav-number">4.</span> <span class="nav-text">Cross Validation: Getting the Best Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Conclusion"><span class="nav-number">5.</span> <span class="nav-text">Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Bania</p>
  <div class="site-description" itemprop="description">A platform for discussing programming and technology</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bania</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div>

<div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv" style='display:none'>
  Total visits: <span id="busuanzi_value_site_pv"></span> times
  <span class="post-meta-divider">|</span>
</span>
<span id="busuanzi_container_site_uv" style='display:none'>
  <span id="busuanzi_value_site_uv"></span>people have viewed my bolg.
</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
